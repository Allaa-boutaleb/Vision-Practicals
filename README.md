# Vision-Practicals
A series of solved Computer Vision practicals during the final Masters Year (M2 DAC) at Sorbonne University.


The computer vision practicals outlined provide a structured approach to understanding and applying advanced deep learning concepts tailored for visual data processing. Here is a breakdown of each practical's focus:

## SECTION 1: Computer Vision Basics
**1-ab: Intro to Neural Networks**  
In this practical, we introduce the core concepts of neural networks, which are foundational to modern AI systems. We explore the structure of neural networks and the principles of learning through backpropagation, essential for optimizing their performance.

**1-cd: Convolutional Neural Networks (CNNs)**  
This session focuses on CNNs, examining their specialized architecture that excels in processing pixel data. We discuss the layers that help in identifying features in images, making CNNs effective for tasks such as image classification and face recognition.

**1-e: Transformers**  
We introduce transformers in this practical, a newer class of deep learning models known for their effectiveness in handling sequential data. Transformers are notable for their ability to capture global dependencies in data, making them superior in areas like image captioning and object detection compared to traditional RNNs and CNNs.

## SECTION 2: Deep Learning Applications
**2-a: Transfer Learning**  
We delve into transfer learning, discussing how to leverage pre-trained models for new problems with limited data. This approach is pivotal for enhancing learning efficiency and improving model performance across different tasks by transferring knowledge from one domain to another.

**2-b: Visualization**  
In this practical, we focus on the visualization of neural networks, which helps in understanding and interpreting the model's decisions and workings. Visualization techniques are crucial for diagnosing model performance and for explaining the outcomes to stakeholders.

**2-c: Domain Adaptation**  
We explore domain adaptation, a technique to improve model performance under varying input distributions. This practical teaches strategies to adapt models trained on one set of data (source domain) to perform well on a different set of data (target domain).

**2-de: Generative Adversarial Networks (GANs)**  
This session covers GANs, which are systems consisting of two neural networks contesting with each other. We explain how these networks can generate new data instances that are similar to the training data, useful in applications like image synthesis and enhancement.

## SECTION 3: Bayesian Deep Learning
**3-a: Bayesian Linear Regression**  
We introduce Bayesian linear regression, providing a probabilistic perspective to regression problems. This approach allows for the incorporation of prior knowledge and uncertainty in predictions, making the model robust to overfitting and providing confidence intervals along with predictions.

**3-b: Approximate Inference**  
In this practical, we discuss approximate inference techniques in the context of Bayesian models. We cover methods that allow for practical application of Bayesian approaches in large datasets where exact inference is computationally infeasible.

**3-c: Applications of Uncertainty**  
Finally, we examine how modeling uncertainty can be applied in real-world scenarios. This practical highlights the importance of understanding and quantifying uncertainty in model predictions, enhancing decision-making processes in critical applications like medical imaging and autonomous driving.
